{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Syntax Basics\n",
    "\n",
    "With TensorFlow 2.0 , Keras is now the main API choice. Let's work through a simple regression project to understand the basics of the Keras syntax and adding layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "To learn the basic syntax of Keras, we will use a very simple fake data set, in the subsequent lectures we will focus on real datasets, along with feature engineering! For now, let's focus on the syntax of TensorFlow 2.0.\n",
    "\n",
    "Let's pretend this data are measurements of some rare gem stones, with 2 measurement features and a sale price. Our final goal would be to try to predict the sale price of a new gem stone we just mined from the ground, in order to try to set a fair price in the market.\n",
    "\n",
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/q2/pyrq5k_s7gz_4v527qy_7lcc0000gn/T/ipykernel_49681/4080736814.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/q2/pyrq5k_s7gz_4v527qy_7lcc0000gn/T/ipykernel_49681/4080736814.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/q2/pyrq5k_s7gz_4v527qy_7lcc0000gn/T/ipykernel_49681/4080736814.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 52, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/anshulchiranth/anaconda3/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.rec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../DATA/fake_reg.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[0;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m   1969\u001b[0m         new_col_dict,\n\u001b[1;32m   1970\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   1971\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   1972\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[1;32m   1973\u001b[0m     )\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:444\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[1;32m    443\u001b[0m arrays \u001b[38;5;241m=\u001b[39m Series(data, index\u001b[38;5;241m=\u001b[39mcolumns, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m--> 444\u001b[0m missing \u001b[38;5;241m=\u001b[39m arrays\u001b[38;5;241m.\u001b[39misna()\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# GH10856\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# raise ValueError if only scalars in dict\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     index \u001b[38;5;241m=\u001b[39m _extract_index(arrays[\u001b[38;5;241m~\u001b[39mmissing])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:5786\u001b[0m, in \u001b[0;36mSeries.isna\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5784\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39misna, klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m-> 5786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39misna(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:8773\u001b[0m, in \u001b[0;36mNDFrame.isna\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8712\u001b[0m \u001b[38;5;129m@doc\u001b[39m(klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   8713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   8714\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8715\u001b[0m \u001b[38;5;124;03m    Detect missing values.\u001b[39;00m\n\u001b[1;32m   8716\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8771\u001b[0m \u001b[38;5;124;03m    dtype: bool\u001b[39;00m\n\u001b[1;32m   8772\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m isna(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misna\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna(obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:216\u001b[0m, in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isna_array(obj\u001b[38;5;241m.\u001b[39m_values, inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCSeries):\n\u001b[0;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m _isna_array(obj\u001b[38;5;241m.\u001b[39m_values, inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# box\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:288\u001b[0m, in \u001b[0;36m_isna_array\u001b[0;34m(values, inf_as_na)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;66;03m# \"Union[ndarray[Any, Any], ExtensionArraySupportsAnyAll]\", variable has\u001b[39;00m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;66;03m# type \"ndarray[Any, dtype[bool_]]\")\u001b[39;00m\n\u001b[1;32m    287\u001b[0m         result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39misna()  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mrec\u001b[38;5;241m.\u001b[39mrecarray):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# GH 48526\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     result \u001b[38;5;241m=\u001b[39m _isna_recarray_dtype(values, inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_string_or_object_np_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:367\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Throw runtime error, if the test failed Check for warning and error_message\u001b[39;00m\n\u001b[1;32m    366\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    368\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(w[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(w[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage))\n\u001b[1;32m    369\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolyfit sanity test emitted a warning, most likely due \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto using a buggy Accelerate backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOtherwise report this to the vendor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat provided NumPy.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error_message))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.rec'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../DATA/fake_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "Let's take a quick look, we should see strong correlation between the features and the \"price\" of this made up product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sns\u001b[38;5;241m.\u001b[39mpairplot(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to visualize more, but this data is fake, so we will focus on feature engineering and exploratory data analysis later on in the course in much more detail!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.rec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py:83\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compress, islice\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/__init__.py:78\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m _fun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(np, _key)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_fun, _types\u001b[38;5;241m.\u001b[39mModuleType):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:367\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Throw runtime error, if the test failed Check for warning and error_message\u001b[39;00m\n\u001b[1;32m    366\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    368\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(w[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(w[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage))\n\u001b[1;32m    369\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolyfit sanity test emitted a warning, most likely due \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto using a buggy Accelerate backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOtherwise report this to the vendor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat provided NumPy.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error_message))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.rec'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert Pandas to Numpy for Keras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Features\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature2\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Label\u001b[39;00m\n\u001b[1;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert Pandas to Numpy for Keras\n",
    "\n",
    "# Features\n",
    "X = df[['feature1','feature2']].values\n",
    "\n",
    "# Label\n",
    "y = df['price'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_train\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing/Scaling the Data\n",
    "\n",
    "We scale the feature data.\n",
    "\n",
    "[Why we don't need to scale the label](https://stats.stackexchange.com/questions/111467/is-it-necessary-to-scale-the-target-value-in-addition-to-scaling-features-for-re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.rec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py:83\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compress, islice\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/__init__.py:78\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m _fun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(np, _key)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_fun, _types\u001b[38;5;241m.\u001b[39mModuleType):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:367\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# Throw runtime error, if the test failed Check for warning and error_message\u001b[39;00m\n\u001b[1;32m    366\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    368\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(w[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(w[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage))\n\u001b[1;32m    369\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolyfit sanity test emitted a warning, most likely due \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto using a buggy Accelerate backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOtherwise report this to the vendor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat provided NumPy.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error_message))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.rec'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m help(MinMaxScaler)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "help(MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice to prevent data leakage from the test set, we only fit our scaler to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scaler\u001b[38;5;241m.\u001b[39mfit(X_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[1;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 Syntax\n",
    "\n",
    "\n",
    "## Import Options\n",
    "\n",
    "There are several ways you can import Keras from Tensorflow (this is hugely a personal style choice, please use any import methods you prefer). We will use the method shown in the **official TF documentation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV bindings requires \"numpy\" package.\n",
      "Install it via command:\n",
      "    pip install numpy\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\r\n",
      "Version: 1.23.5\r\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\r\n",
      "Home-page: https://www.numpy.org\r\n",
      "Author: Travis E. Oliphant et al.\r\n",
      "Author-email: \r\n",
      "License: BSD\r\n",
      "Location: /Users/anshulchiranth/anaconda3/lib/python3.11/site-packages\r\n",
      "Requires: \r\n",
      "Required-by: ale-py, astropy, bayesian-optimization, bokeh, Bottleneck, cftime, cma, contourpy, coreforecast, ctgan, cufflinks, datasets, datashader, datashape, directsearch, gensim, gym, h5py, holoviews, hvplot, imagecodecs, imageio, imbalanced-learn, keras, keras-nightly, matplotlib, ml_dtypes, mne, mne-connectivity, netCDF4, neuralforecast, nevergrad, numba, numexpr, opencv-python, optuna, pandas, patsy, pmdarima, pyarrow, pydeck, pyerfa, pyvista, PyWavelets, rdt, scikit-image, scikit-learn, scipy, seaborn, statsforecast, statsmodels, streamlit, tables, tb-nightly, tensorboard, tensorboardX, tensorflow, tf_nightly, tifffile, torchmetrics, torchvision, transformers, triad, utilsforecast, xarray\r\n"
     ]
    }
   ],
   "source": [
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.19.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /Users/anshulchiranth/anaconda3/lib/python3.11/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sequential in module keras.src.models.sequential:\n",
      "\n",
      "class Sequential(keras.src.models.model.Model)\n",
      " |  Sequential(*args, **kwargs)\n",
      " |  \n",
      " |  `Sequential` groups a linear stack of layers into a `Model`.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  ```python\n",
      " |  model = keras.Sequential()\n",
      " |  model.add(keras.Input(shape=(16,)))\n",
      " |  model.add(keras.layers.Dense(8))\n",
      " |  \n",
      " |  # Note that you can also omit the initial `Input`.\n",
      " |  # In that case the model doesn't have any weights until the first call\n",
      " |  # to a training/evaluation method (since it isn't yet built):\n",
      " |  model = keras.Sequential()\n",
      " |  model.add(keras.layers.Dense(8))\n",
      " |  model.add(keras.layers.Dense(4))\n",
      " |  # model.weights not created yet\n",
      " |  \n",
      " |  # Whereas if you specify an `Input`, the model gets built\n",
      " |  # continuously as you are adding layers:\n",
      " |  model = keras.Sequential()\n",
      " |  model.add(keras.Input(shape=(16,)))\n",
      " |  model.add(keras.layers.Dense(8))\n",
      " |  len(model.weights)  # Returns \"2\"\n",
      " |  \n",
      " |  # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  # choose to manually build your model by calling\n",
      " |  # `build(batch_input_shape)`:\n",
      " |  model = keras.Sequential()\n",
      " |  model.add(keras.layers.Dense(8))\n",
      " |  model.add(keras.layers.Dense(4))\n",
      " |  model.build((None, 16))\n",
      " |  len(model.weights)  # Returns \"4\"\n",
      " |  \n",
      " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
      " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
      " |  # or the first time you call the model on some input data.\n",
      " |  model = keras.Sequential()\n",
      " |  model.add(keras.layers.Dense(8))\n",
      " |  model.add(keras.layers.Dense(1))\n",
      " |  model.compile(optimizer='sgd', loss='mse')\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      keras.src.models.model.Model\n",
      " |      keras.src.backend.tensorflow.trainer.TensorFlowTrainer\n",
      " |      keras.src.trainers.trainer.Trainer\n",
      " |      keras.src.layers.layer.Layer\n",
      " |      keras.src.backend.tensorflow.layer.TFLayer\n",
      " |      keras.src.backend.tensorflow.trackable.KerasAutoTrackable\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.src.ops.operation.Operation\n",
      " |      keras.src.saving.keras_saveable.KerasSaveable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, trainable=True, name=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add(self, layer, rebuild=True)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Args:\n",
      " |          layer: layer instance.\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None, **kwargs)\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |  \n",
      " |  compute_output_spec(self, inputs, training=None, mask=None, **kwargs)\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the object.\n",
      " |      \n",
      " |      An object config is a Python dictionary (serializable)\n",
      " |      containing the information needed to re-instantiate it.\n",
      " |  \n",
      " |  pop(self, rebuild=True)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Args:\n",
      " |          rebuild: `bool`. Whether to rebuild the model after removing\n",
      " |          the layer. Defaults to `True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          layer: layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Creates an operation from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`, capable of instantiating the\n",
      " |      same operation from the config dictionary.\n",
      " |      \n",
      " |      Note: If you override this method, you might receive a serialized dtype\n",
      " |      config, which is a `dict`. You can deserialize it as follows:\n",
      " |      \n",
      " |      ```python\n",
      " |      if \"dtype\" in config and isinstance(config[\"dtype\"], dict):\n",
      " |          policy = dtype_policies.deserialize(config[\"dtype\"])\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the output of `get_config`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An operation instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  input_dtype\n",
      " |      The dtype layer inputs should be converted to.\n",
      " |  \n",
      " |  input_shape\n",
      " |  \n",
      " |  inputs\n",
      " |  \n",
      " |  output_shape\n",
      " |  \n",
      " |  outputs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.models.model.Model:\n",
      " |  \n",
      " |  build_from_config(self, config)\n",
      " |      Builds the layer's states with the supplied config dict.\n",
      " |      \n",
      " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
      " |      which creates weights based on the layer's input shape in the supplied\n",
      " |      config. If your config contains other information needed to load the\n",
      " |      layer's state, you should override this method.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Dict containing the input shape associated with this layer.\n",
      " |  \n",
      " |  export(self, filepath, format='tf_saved_model', verbose=None, input_signature=None, **kwargs)\n",
      " |      Export the model as an artifact for inference.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: `str` or `pathlib.Path` object. The path to save the\n",
      " |              artifact.\n",
      " |          format: `str`. The export format. Supported values:\n",
      " |              `\"tf_saved_model\"` and `\"onnx\"`.  Defaults to\n",
      " |              `\"tf_saved_model\"`.\n",
      " |          verbose: `bool`. Whether to print a message during export. Defaults\n",
      " |              to `None`, which uses the default value set by different\n",
      " |              backends and formats.\n",
      " |          input_signature: Optional. Specifies the shape and dtype of the\n",
      " |              model inputs. Can be a structure of `keras.InputSpec`,\n",
      " |              `tf.TensorSpec`, `backend.KerasTensor`, or backend tensor. If\n",
      " |              not provided, it will be automatically computed. Defaults to\n",
      " |              `None`.\n",
      " |          **kwargs: Additional keyword arguments:\n",
      " |              - Specific to the JAX backend and `format=\"tf_saved_model\"`:\n",
      " |                  - `is_static`: Optional `bool`. Indicates whether `fn` is\n",
      " |                      static. Set to `False` if `fn` involves state updates\n",
      " |                      (e.g., RNG seeds and counters).\n",
      " |                  - `jax2tf_kwargs`: Optional `dict`. Arguments for\n",
      " |                      `jax2tf.convert`. See the documentation for\n",
      " |                      [`jax2tf.convert`](\n",
      " |                          https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md).\n",
      " |                      If `native_serialization` and `polymorphic_shapes` are\n",
      " |                      not provided, they will be automatically computed.\n",
      " |      \n",
      " |      **Note:** This feature is currently supported only with TensorFlow, JAX\n",
      " |      and Torch backends.\n",
      " |      \n",
      " |      **Note:** Be aware that the exported artifact may contain information\n",
      " |      from the local file system when using `format=\"onnx\"`, `verbose=True`\n",
      " |      and Torch backend.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      Here's how to export a TensorFlow SavedModel for inference.\n",
      " |      \n",
      " |      ```python\n",
      " |      # Export the model as a TensorFlow SavedModel artifact\n",
      " |      model.export(\"path/to/location\", format=\"tf_saved_model\")\n",
      " |      \n",
      " |      # Load the artifact in a different process/environment\n",
      " |      reloaded_artifact = tf.saved_model.load(\"path/to/location\")\n",
      " |      predictions = reloaded_artifact.serve(input_data)\n",
      " |      ```\n",
      " |      \n",
      " |      Here's how to export an ONNX for inference.\n",
      " |      \n",
      " |      ```python\n",
      " |      # Export the model as a ONNX artifact\n",
      " |      model.export(\"path/to/location\", format=\"onnx\")\n",
      " |      \n",
      " |      # Load the artifact in a different process/environment\n",
      " |      ort_session = onnxruntime.InferenceSession(\"path/to/location\")\n",
      " |      ort_inputs = {\n",
      " |          k.name: v for k, v in zip(ort_session.get_inputs(), input_data)\n",
      " |      }\n",
      " |      predictions = ort_session.run(None, ort_inputs)\n",
      " |      ```\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Args:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  get_state_tree(self, value_format='backend_tensor')\n",
      " |      Retrieves tree-like structure of model variables.\n",
      " |      \n",
      " |      This method allows retrieval of different model variables (trainable,\n",
      " |      non-trainable, optimizer, and metrics). The variables are returned in a\n",
      " |      nested dictionary format, where the keys correspond to the variable\n",
      " |      names and the values are the nested representations of the variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict: A dictionary containing the nested representations of the\n",
      " |              requested variables. The keys are the variable names, and the\n",
      " |              values are the corresponding nested dictionaries.\n",
      " |          value_format: One of `\"backend_tensor\"`, `\"numpy_array\"`.\n",
      " |              The kind of array to return as the leaves of the nested\n",
      " |                  state tree.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      model = keras.Sequential([\n",
      " |          keras.Input(shape=(1,), name=\"my_input\"),\n",
      " |          keras.layers.Dense(1, activation=\"sigmoid\", name=\"my_dense\"),\n",
      " |      ], name=\"my_sequential\")\n",
      " |      model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      model.fit(np.array([[1.0]]), np.array([[1.0]]))\n",
      " |      state_tree = model.get_state_tree()\n",
      " |      ```\n",
      " |      \n",
      " |      The `state_tree` dictionary returned looks like:\n",
      " |      \n",
      " |      ```\n",
      " |      {\n",
      " |          'metrics_variables': {\n",
      " |              'loss': {\n",
      " |                  'count': ...,\n",
      " |                  'total': ...,\n",
      " |              },\n",
      " |              'mean_absolute_error': {\n",
      " |                  'count': ...,\n",
      " |                  'total': ...,\n",
      " |              }\n",
      " |          },\n",
      " |          'trainable_variables': {\n",
      " |              'my_sequential': {\n",
      " |                  'my_dense': {\n",
      " |                      'bias': ...,\n",
      " |                      'kernel': ...,\n",
      " |                  }\n",
      " |              }\n",
      " |          },\n",
      " |          'non_trainable_variables': {},\n",
      " |          'optimizer_variables': {\n",
      " |              'adam': {\n",
      " |                      'iteration': ...,\n",
      " |                      'learning_rate': ...,\n",
      " |                      'my_sequential_my_dense_bias_momentum': ...,\n",
      " |                      'my_sequential_my_dense_bias_velocity': ...,\n",
      " |                      'my_sequential_my_dense_kernel_momentum': ...,\n",
      " |                      'my_sequential_my_dense_kernel_velocity': ...,\n",
      " |                  }\n",
      " |              }\n",
      " |          }\n",
      " |      }\n",
      " |      ```\n",
      " |  \n",
      " |  load_weights(self, filepath, skip_mismatch=False, **kwargs)\n",
      " |      Load the weights from a single file or sharded files.\n",
      " |      \n",
      " |      Weights are loaded based on the network's topology. This means the\n",
      " |      architecture should be the same as when the weights were saved. Note\n",
      " |      that layers that don't have weights are not taken into account in the\n",
      " |      topological ordering, so adding or removing layers is fine as long as\n",
      " |      they don't have weights.\n",
      " |      \n",
      " |      **Partial weight loading**\n",
      " |      \n",
      " |      If you have modified your model, for instance by adding a new layer\n",
      " |      (with weights) or by changing the shape of the weights of a layer, you\n",
      " |      can choose to ignore errors and continue loading by setting\n",
      " |      `skip_mismatch=True`. In this case any layer with mismatching weights\n",
      " |      will be skipped. A warning will be displayed for each skipped layer.\n",
      " |      \n",
      " |      **Sharding**\n",
      " |      \n",
      " |      When loading sharded weights, it is important to specify `filepath` that\n",
      " |      ends with `*.weights.json` which is used as the configuration file.\n",
      " |      Additionally, the sharded files `*_xxxxx.weights.h5` must be in the same\n",
      " |      directory as the configuration file.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: `str` or `pathlib.Path` object. Path where the weights\n",
      " |              will be saved.  When sharding, the filepath must end in\n",
      " |              `.weights.json`.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where\n",
      " |              there is a mismatch in the number of weights, or a mismatch in\n",
      " |              the shape of the weights.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      # Load the weights in a single file.\n",
      " |      model.load_weights(\"model.weights.h5\")\n",
      " |      \n",
      " |      # Load the weights in sharded files.\n",
      " |      model.load_weights(\"model.weights.json\")\n",
      " |      ```\n",
      " |  \n",
      " |  quantize(self, mode, **kwargs)\n",
      " |      Quantize the weights of the model.\n",
      " |      \n",
      " |      Note that the model must be built first before calling this method.\n",
      " |      `quantize` will recursively call `quantize(mode)` in all layers and\n",
      " |      will be skipped if the layer doesn't implement the function.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode: The mode of the quantization. Only 'int8' is supported at this\n",
      " |              time.\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, zipped=None, **kwargs)\n",
      " |      Saves a model as a `.keras` file.\n",
      " |      \n",
      " |      Note that `model.save()` is an alias for `keras.saving.save_model()`.\n",
      " |      \n",
      " |      The saved `.keras` file contains:\n",
      " |      \n",
      " |      - The model's configuration (architecture)\n",
      " |      - The model's weights\n",
      " |      - The model's optimizer's state (if any)\n",
      " |      \n",
      " |      Thus models can be reinstantiated in the exact same state.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: `str` or `pathlib.Path` object.\n",
      " |              The path where to save the model. Must end in `.keras`\n",
      " |              (unless saving the model as an unzipped directory\n",
      " |              via `zipped=False`).\n",
      " |          overwrite: Whether we should overwrite any existing model at\n",
      " |              the target location, or instead ask the user via\n",
      " |              an interactive prompt.\n",
      " |          zipped: Whether to save the model as a zipped `.keras`\n",
      " |              archive (default when saving locally), or as an\n",
      " |              unzipped directory (default when saving on the\n",
      " |              Hugging Face Hub).\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      model = keras.Sequential(\n",
      " |          [\n",
      " |              keras.layers.Dense(5, input_shape=(3,)),\n",
      " |              keras.layers.Softmax(),\n",
      " |          ],\n",
      " |      )\n",
      " |      model.save(\"model.keras\")\n",
      " |      loaded_model = keras.saving.load_model(\"model.keras\")\n",
      " |      x = keras.random.uniform((10, 3))\n",
      " |      assert np.allclose(model.predict(x), loaded_model.predict(x))\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, max_shard_size=None)\n",
      " |      Saves all weights to a single file or sharded files.\n",
      " |      \n",
      " |      By default, the weights will be saved in a single `.weights.h5` file.\n",
      " |      If sharding is enabled (`max_shard_size` is not `None`), the weights\n",
      " |      will be saved in multiple files, each with a size at most\n",
      " |      `max_shard_size` (in GB). Additionally, a configuration file\n",
      " |      `.weights.json` will contain the metadata for the sharded files.\n",
      " |      \n",
      " |      The saved sharded files contain:\n",
      " |      \n",
      " |      - `*.weights.json`: The configuration file containing 'metadata' and\n",
      " |          'weight_map'.\n",
      " |      - `*_xxxxxx.weights.h5`: The sharded files containing only the\n",
      " |          weights.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath: `str` or `pathlib.Path` object. Path where the weights\n",
      " |              will be saved.  When sharding, the filepath must end in\n",
      " |              `.weights.json`. If `.weights.h5` is provided, it will be\n",
      " |              overridden.\n",
      " |          overwrite: Whether to overwrite any existing weights at the target\n",
      " |              location or instead ask the user via an interactive prompt.\n",
      " |          max_shard_size: `int` or `float`. Maximum size in GB for each\n",
      " |              sharded file. If `None`, no sharding will be done. Defaults to\n",
      " |              `None`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      # Instantiate a EfficientNetV2L model with about 454MB of weights.\n",
      " |      model = keras.applications.EfficientNetV2L(weights=None)\n",
      " |      \n",
      " |      # Save the weights in a single file.\n",
      " |      model.save_weights(\"model.weights.h5\")\n",
      " |      \n",
      " |      # Save the weights in sharded files. Use `max_shard_size=0.25` means\n",
      " |      # each sharded file will be at most ~250MB.\n",
      " |      model.save_weights(\"model.weights.json\", max_shard_size=0.25)\n",
      " |      \n",
      " |      # Load the weights in a new model with the same architecture.\n",
      " |      loaded_model = keras.applications.EfficientNetV2L(weights=None)\n",
      " |      loaded_model.load_weights(\"model.weights.h5\")\n",
      " |      x = keras.random.uniform((1, 480, 480, 3))\n",
      " |      assert np.allclose(model.predict(x), loaded_model.predict(x))\n",
      " |      \n",
      " |      # Load the sharded weights in a new model with the same architecture.\n",
      " |      loaded_model = keras.applications.EfficientNetV2L(weights=None)\n",
      " |      loaded_model.load_weights(\"model.weights.json\")\n",
      " |      x = keras.random.uniform((1, 480, 480, 3))\n",
      " |      assert np.allclose(model.predict(x), loaded_model.predict(x))\n",
      " |      ```\n",
      " |  \n",
      " |  set_state_tree(self, state_tree)\n",
      " |      Assigns values to variables of the model.\n",
      " |      \n",
      " |      This method takes a dictionary of nested variable values, which\n",
      " |      represents the state tree of the model, and assigns them to the\n",
      " |      corresponding variables of the model. The dictionary keys represent the\n",
      " |      variable names (e.g., `'trainable_variables'`, `'optimizer_variables'`),\n",
      " |      and the values are nested dictionaries containing the variable\n",
      " |      paths and their corresponding values.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_tree: A dictionary representing the state tree of the model.\n",
      " |              The keys are the variable names, and the values are nested\n",
      " |              dictionaries representing the variable paths and their values.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Args:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided, becomes\n",
      " |              `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n",
      " |          print_fn: Print function to use. By default, prints to `stdout`.\n",
      " |              If `stdout` doesn't work in your environment, change to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |          expand_nested: Whether to expand the nested models.\n",
      " |              Defaults to `False`.\n",
      " |          show_trainable: Whether to show if a layer is trainable.\n",
      " |              Defaults to `False`.\n",
      " |          layer_range: a list or tuple of 2 strings,\n",
      " |              which is the starting layer name and ending layer name\n",
      " |              (both inclusive) indicating the range of layers to be printed\n",
      " |              in summary. It also accepts regex patterns instead of exact\n",
      " |              names. In this case, the start predicate will be\n",
      " |              the first element that matches `layer_range[0]`\n",
      " |              and the end predicate will be the last element\n",
      " |              that matches `layer_range[1]`.\n",
      " |              By default `None` considers all layers of the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={...})`.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments to be passed to\n",
      " |              `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.backend.tensorflow.trainer.TensorFlowTrainer:\n",
      " |  \n",
      " |  compiled_loss(self, y, y_pred, sample_weight=None, regularization_losses=None)\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose='auto', sample_weight=None, steps=None, callbacks=None, return_dict=False, **kwargs)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It can be:\n",
      " |              - A NumPy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |              - A backend-native tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |              - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |              - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |              - A `tf.data.Dataset` yielding `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |              - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |              - A Python generator function yielding `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |          y: Target data. Like the input data `x`, it can be either NumPy\n",
      " |              array(s) or backend-native tensor(s). If `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or a Python generator function,\n",
      " |              `y` should not be specified since targets will be obtained from\n",
      " |              `x`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch of computation.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your input data `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function\n",
      " |              since they generate batches.\n",
      " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = single line.\n",
      " |              `\"auto\"` becomes 1 for most cases.\n",
      " |              Note that the progress bar is not\n",
      " |              particularly useful when logged to a file, so `verbose=2` is\n",
      " |              recommended when not running interactively\n",
      " |              (e.g. in a production environment). Defaults to `\"auto\"`.\n",
      " |          sample_weight: Optional NumPy array or tensor of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              NumPy array or tensor with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |              temporal data, you can pass a 2D NumPy array or tensor with\n",
      " |              shape `(samples, sequence_length)` to apply a different weight\n",
      " |              to every timestep of every sample.\n",
      " |              This argument is not supported when `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function.\n",
      " |              Instead, provide `sample_weights` as the third element of `x`.\n",
      " |              Note that sample weighting does not apply to metrics specified\n",
      " |              via the `metrics` argument in `compile()`. To apply sample\n",
      " |              weighting to your metrics, you can specify them via the\n",
      " |              `weighted_metrics` in `compile()` instead.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples) to draw before\n",
      " |              declaring the evaluation round finished. If `steps` is `None`,\n",
      " |              it will run until `x` is exhausted. In the case of an infinitely\n",
      " |              repeating dataset, it will run indefinitely.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a\n",
      " |              dict, with each key being the name of the metric.\n",
      " |              If `False`, they are returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1)\n",
      " |      Trains the model for a fixed number of epochs (dataset iterations).\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It can be:\n",
      " |              - A NumPy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |              - A backend-native tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |              - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |              - A `keras.utils.PyDataset` returning `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |              - A `tf.data.Dataset` yielding `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |              - A `torch.utils.data.DataLoader` yielding `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |              - A Python generator function yielding `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |          y: Target data. Like the input data `x`, it can be either NumPy\n",
      " |              array(s) or backend-native tensor(s). If `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or a Python generator function,\n",
      " |              `y` should not be specified since targets will be obtained from\n",
      " |              `x`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your input data `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function\n",
      " |              since they generate batches.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided\n",
      " |              (unless the `steps_per_epoch` flag is set to\n",
      " |              something other than None).\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              \"auto\" becomes 1 for most cases.\n",
      " |              Note that the progress bar is not\n",
      " |              particularly useful when logged to a file,\n",
      " |              so `verbose=2` is recommended when not running interactively\n",
      " |              (e.g., in a production environment). Defaults to `\"auto\"`.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `keras.callbacks`. Note\n",
      " |              `keras.callbacks.ProgbarLogger` and\n",
      " |              `keras.callbacks.History` callbacks are created\n",
      " |              automatically and need not be passed to `model.fit()`.\n",
      " |              `keras.callbacks.ProgbarLogger` is created\n",
      " |              or not based on the `verbose` argument in `model.fit()`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate the loss and any model\n",
      " |              metrics on this data at the end of each epoch. The validation\n",
      " |              data is selected from the last samples in the `x` and `y` data\n",
      " |              provided, before shuffling.\n",
      " |              This argument is only supported when `x` and `y` are made of\n",
      " |              NumPy arrays or tensors.\n",
      " |              If both `validation_data` and `validation_split` are provided,\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using\n",
      " |              `validation_split` or `validation_data` is not affected by\n",
      " |              regularization layers like noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              It can be:\n",
      " |              - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
      " |              - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      " |              arrays.\n",
      " |              - A `keras.utils.PyDataset`, a `tf.data.Dataset`, a\n",
      " |              `torch.utils.data.DataLoader` yielding `(inputs, targets)` or a\n",
      " |              Python generator function yielding `(x_val, y_val)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |          shuffle: Boolean, whether to shuffle the training data before each\n",
      " |              epoch. This argument is ignored when `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class. When `class_weight` is specified\n",
      " |              and targets have a rank of 2 or greater, either `y` must be\n",
      " |              one-hot encoded, or an explicit final dimension of `1` must\n",
      " |              be included for sparse class labels.\n",
      " |          sample_weight: Optional NumPy array or tensor of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              NumPy array or tensor with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |              temporal data, you can pass a 2D NumPy array or tensor with\n",
      " |              shape `(samples, sequence_length)` to apply a different weight\n",
      " |              to every timestep of every sample.\n",
      " |              This argument is not supported when `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function.\n",
      " |              Instead, provide `sample_weights` as the third element of `x`.\n",
      " |              Note that sample weighting does not apply to metrics specified\n",
      " |              via the `metrics` argument in `compile()`. To apply sample\n",
      " |              weighting to your metrics, you can specify them via the\n",
      " |              `weighted_metrics` in `compile()` instead.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples) before declaring one\n",
      " |              epoch finished and starting the next epoch. When training with\n",
      " |              input tensors or NumPy arrays, the default `None` means that the\n",
      " |              value used is the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined.\n",
      " |              If `x` is a `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function, the\n",
      " |              epoch will run until the input dataset is exhausted. When\n",
      " |              passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument, otherwise the training will run\n",
      " |              indefinitely.\n",
      " |          validation_steps: Integer or `None`.\n",
      " |              Only relevant if `validation_data` is provided.\n",
      " |              Total number of steps (batches of samples) to draw before\n",
      " |              stopping when performing validation at the end of every epoch.\n",
      " |              If `validation_steps` is `None`, validation will run until the\n",
      " |              `validation_data` dataset is exhausted. In the case of an\n",
      " |              infinitely repeating dataset, it will run indefinitely. If\n",
      " |              `validation_steps` is specified and only part of the dataset\n",
      " |              is consumed, the evaluation will start from the beginning of the\n",
      " |              dataset at each epoch. This ensures that the same validation\n",
      " |              samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function\n",
      " |              since they generate batches.\n",
      " |          validation_freq: Only relevant if validation data is provided.\n",
      " |              Specifies how many training epochs to run\n",
      " |              before a new validation run is performed,\n",
      " |              e.g. `validation_freq=2` runs validation every 2 epochs.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass an iterator like object such as a\n",
      " |          `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
      " |          which will in fact yield not only features (`x`)\n",
      " |          but optionally targets (`y`) and sample weights (`sample_weight`).\n",
      " |          Keras requires that the output of such iterator-likes be\n",
      " |          unambiguous. The iterator should return a tuple\n",
      " |          of length 1, 2, or 3, where the optional second and third elements\n",
      " |          will be used for `y` and `sample_weight` respectively.\n",
      " |          Any other type provided will be wrapped in\n",
      " |          a length-one tuple, effectively treating everything as `x`. When\n",
      " |          yielding dicts, they should still adhere to the top-level tuple\n",
      " |          structure,\n",
      " |          e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |          features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the `namedtuple`. The reason is\n",
      " |          that it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |          datatype (dict). So given a namedtuple of the form:\n",
      " |          `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |          it is ambiguous whether to reverse the order of the elements when\n",
      " |          interpreting the value. Even worse is a tuple of the form:\n",
      " |          `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |          where it is unclear if the tuple was intended to be unpacked\n",
      " |          into `x`, `y`, and `sample_weight` or passed through\n",
      " |          as a single element to `x`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |  \n",
      " |  loss(self, y, y_pred, sample_weight=None)\n",
      " |  \n",
      " |  make_predict_function(self, force=False)\n",
      " |  \n",
      " |  make_test_function(self, force=False)\n",
      " |  \n",
      " |  make_train_function(self, force=False)\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose='auto', steps=None, callbacks=None)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for batch\n",
      " |      processing of large numbers of inputs. It is not intended for use inside\n",
      " |      of loops that iterate over your data and process small numbers of inputs\n",
      " |      at a time.\n",
      " |      \n",
      " |      For small numbers of inputs that fit in one batch,\n",
      " |      directly use `__call__()` for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `BatchNormalization` that behave differently during\n",
      " |      inference.\n",
      " |      \n",
      " |      Note: See [this FAQ entry](\n",
      " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
      " |      for more details about the difference between `Model` methods\n",
      " |      `predict()` and `__call__()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It can be:\n",
      " |              - A NumPy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |              - A backend-native tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |              - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |              - A `keras.utils.PyDataset`.\n",
      " |              - A `tf.data.Dataset`.\n",
      " |              - A `torch.utils.data.DataLoader`.\n",
      " |              - A Python generator function.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch of computation.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your input data `x` is a\n",
      " |              `keras.utils.PyDataset`, `tf.data.Dataset`,\n",
      " |              `torch.utils.data.DataLoader` or Python generator function\n",
      " |              since they generate batches.\n",
      " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = single line.\n",
      " |              `\"auto\"` becomes 1 for most cases. Note that the progress bar\n",
      " |              is not particularly useful when logged to a file,\n",
      " |              so `verbose=2` is recommended when not running interactively\n",
      " |              (e.g. in a production environment). Defaults to `\"auto\"`.\n",
      " |          steps: Total number of steps (batches of samples) to draw before\n",
      " |              declaring the prediction round finished. If `steps` is `None`,\n",
      " |              it will run until `x` is exhausted. In the case of an infinitely\n",
      " |              repeating dataset, it will run indefinitely.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          NumPy array(s) of predictions.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. It must be array-like.\n",
      " |      \n",
      " |      Returns:\n",
      " |          NumPy array(s) of predictions.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. Must be array-like.\n",
      " |          y: Target data. Must be array-like.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape `(samples, sequence_length)`, to apply a different\n",
      " |              weight to every timestep of every sample.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a\n",
      " |              dict, with each key being the name of the metric. If `False`,\n",
      " |              they are returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A scalar loss value (when no metrics and `return_dict=False`),\n",
      " |          a list of loss and metric values\n",
      " |          (if there are metrics and `return_dict=False`), or a dict of\n",
      " |          metric and loss values (if `return_dict=True`).\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data. Must be array-like.\n",
      " |          y: Target data. Must be array-like.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape `(samples, sequence_length)`, to apply a different\n",
      " |              weight to every timestep of every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) to apply to the model's loss for the samples\n",
      " |              from this class during training. This can be useful to tell the\n",
      " |              model to \"pay more attention\" to samples from an\n",
      " |              under-represented class. When `class_weight` is specified\n",
      " |              and targets have a rank of 2 or greater, either `y` must\n",
      " |              be one-hot encoded, or an explicit final dimension of 1\n",
      " |              must be included for sparse class labels.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a\n",
      " |              dict, with each key being the name of the metric. If `False`,\n",
      " |              they are returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A scalar loss value (when no metrics and `return_dict=False`),\n",
      " |          a list of loss and metric values\n",
      " |          (if there are metrics and `return_dict=False`), or a dict of\n",
      " |          metric and loss values (if `return_dict=True`).\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.backend.tensorflow.trainer.TensorFlowTrainer:\n",
      " |  \n",
      " |  compiled_metrics\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.src.backend.tensorflow.trainer.TensorFlowTrainer:\n",
      " |  \n",
      " |  distribute_reduction_method\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.trainers.trainer.Trainer:\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, loss_weights=None, metrics=None, weighted_metrics=None, run_eagerly=False, steps_per_execution=1, jit_compile='auto', auto_scale_loss=True)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      model.compile(\n",
      " |          optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
      " |          loss=keras.losses.BinaryCrossentropy(),\n",
      " |          metrics=[\n",
      " |              keras.metrics.BinaryAccuracy(),\n",
      " |              keras.metrics.FalseNegatives(),\n",
      " |          ],\n",
      " |      )\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |              `keras.optimizers`.\n",
      " |          loss: Loss function. May be a string (name of loss function), or\n",
      " |              a `keras.losses.Loss` instance. See `keras.losses`. A\n",
      " |              loss function is any callable with the signature\n",
      " |              `loss = fn(y_true, y_pred)`, where `y_true` are the ground truth\n",
      " |              values, and `y_pred` are the model's predictions.\n",
      " |              `y_true` should have shape `(batch_size, d0, .. dN)`\n",
      " |              (except in the case of sparse loss functions such as\n",
      " |              sparse categorical crossentropy which expects integer arrays of\n",
      " |              shape `(batch_size, d0, .. dN-1)`).\n",
      " |              `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
      " |              The loss function should return a float tensor.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions of\n",
      " |              different model outputs. The loss value that will be minimized\n",
      " |              by the model will then be the *weighted sum* of all individual\n",
      " |              losses, weighted by the `loss_weights` coefficients.  If a list,\n",
      " |              it is expected to have a 1:1 mapping to the model's outputs. If\n",
      " |              a dict, it is expected to map output names (strings) to scalar\n",
      " |              coefficients.\n",
      " |          metrics: List of metrics to be evaluated by the model during\n",
      " |              training and testing. Each of this can be a string (name of a\n",
      " |              built-in function), function or a `keras.metrics.Metric`\n",
      " |              instance. See `keras.metrics`. Typically you will use\n",
      " |              `metrics=['accuracy']`. A function is any callable with the\n",
      " |              signature `result = fn(y_true, _pred)`. To specify different\n",
      " |              metrics for different outputs of a multi-output model, you could\n",
      " |              also pass a dictionary, such as\n",
      " |              `metrics={'a':'accuracy', 'b':['accuracy', 'mse']}`.\n",
      " |              You can also pass a list to specify a metric or a list of\n",
      " |              metrics for each output, such as\n",
      " |              `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
      " |              or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass\n",
      " |              the strings 'accuracy' or 'acc', we convert this to one of\n",
      " |              `keras.metrics.BinaryAccuracy`,\n",
      " |              `keras.metrics.CategoricalAccuracy`,\n",
      " |              `keras.metrics.SparseCategoricalAccuracy` based on the\n",
      " |              shapes of the targets and of the model output. A similar\n",
      " |              conversion is done for the strings `\"crossentropy\"`\n",
      " |              and `\"ce\"` as well.\n",
      " |              The metrics passed here are evaluated without sample weighting;\n",
      " |              if you would like sample weighting to apply, you can specify\n",
      " |              your metrics via the `weighted_metrics` argument instead.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |              `sample_weight` or `class_weight` during training and testing.\n",
      " |          run_eagerly: Bool. If `True`, this model's forward pass\n",
      " |               will never be compiled. It is recommended to leave this\n",
      " |               as `False` when training (for best performance),\n",
      " |               and to set it to `True` when debugging.\n",
      " |          steps_per_execution: Int. The number of batches to run\n",
      " |              during each a single compiled function call. Running multiple\n",
      " |              batches inside a single compiled function call can\n",
      " |              greatly improve performance on TPUs or small models with a large\n",
      " |              Python overhead. At most, one full epoch will be run each\n",
      " |              execution. If a number larger than the size of the epoch is\n",
      " |              passed, the execution will be truncated to the size of the\n",
      " |              epoch. Note that if `steps_per_execution` is set to `N`,\n",
      " |              `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
      " |              will only be called every `N` batches (i.e. before/after\n",
      " |              each compiled function execution).\n",
      " |              Not supported with the PyTorch backend.\n",
      " |          jit_compile: Bool or `\"auto\"`. Whether to use XLA compilation when\n",
      " |              compiling a model. For `jax` and `tensorflow` backends,\n",
      " |              `jit_compile=\"auto\"` enables XLA compilation if the model\n",
      " |              supports it, and disabled otherwise.\n",
      " |              For `torch` backend, `\"auto\"` will default to eager\n",
      " |              execution and `jit_compile=True` will run with `torch.compile`\n",
      " |              with the `\"inductor\"` backend.\n",
      " |          auto_scale_loss: Bool. If `True` and the model dtype policy is\n",
      " |              `\"mixed_float16\"`, the passed optimizer will be automatically\n",
      " |              wrapped in a `LossScaleOptimizer`, which will dynamically\n",
      " |              scale the loss to prevent underflow.\n",
      " |  \n",
      " |  compile_from_config(self, config)\n",
      " |      Compiles the model with the information given in config.\n",
      " |      \n",
      " |      This method uses the information in the config (optimizer, loss,\n",
      " |      metrics, etc.) to compile the model.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: Dict containing information for compiling the model.\n",
      " |  \n",
      " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None, training=True)\n",
      " |      Compute the total loss, validate it, and return it.\n",
      " |      \n",
      " |      Subclasses can optionally override this method to provide custom loss\n",
      " |      computation logic.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyModel(Model):\n",
      " |          def __init__(self, *args, **kwargs):\n",
      " |              super().__init__(*args, **kwargs)\n",
      " |              self.loss_tracker = metrics.Mean(name='loss')\n",
      " |      \n",
      " |          def compute_loss(self, x, y, y_pred, sample_weight, training=True):\n",
      " |              loss = ops.mean((y_pred - y) ** 2)\n",
      " |              loss += ops.sum(self.losses)\n",
      " |              self.loss_tracker.update_state(loss)\n",
      " |              return loss\n",
      " |      \n",
      " |          def reset_metrics(self):\n",
      " |              self.loss_tracker.reset_state()\n",
      " |      \n",
      " |          @property\n",
      " |          def metrics(self):\n",
      " |              return [self.loss_tracker]\n",
      " |      \n",
      " |      inputs = layers.Input(shape=(10,), name='my_input')\n",
      " |      outputs = layers.Dense(10)(inputs)\n",
      " |      model = MyModel(inputs, outputs)\n",
      " |      model.add_loss(ops.sum(outputs))\n",
      " |      \n",
      " |      optimizer = SGD()\n",
      " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
      " |      dataset = ...\n",
      " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
      " |      print(f\"Custom loss: {model.loss_tracker.result()}\")\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data.\n",
      " |          y: Target data.\n",
      " |          y_pred: Predictions returned by the model (output of `model(x)`)\n",
      " |          sample_weight: Sample weights for weighting the loss function.\n",
      " |          training: Whether we are training or evaluating the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The total loss as a scalar tensor, or `None` if no loss results\n",
      " |          (which is the case when called by `Model.test_step`).\n",
      " |  \n",
      " |  compute_metrics(self, x, y, y_pred, sample_weight=None)\n",
      " |      Update metric states and collect all metrics to be returned.\n",
      " |      \n",
      " |      Subclasses can optionally override this method to provide custom metric\n",
      " |      updating and collection logic. Custom metrics are not passed in\n",
      " |      `compile()`, they can be created in `__init__` or `build`. They are\n",
      " |      automatically tracked and returned by `self.metrics`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyModel(Sequential):\n",
      " |          def __init__(self, *args, **kwargs):\n",
      " |              super().__init__(*args, **kwargs)\n",
      " |              self.custom_metric = MyMetric(name=\"custom_metric\")\n",
      " |      \n",
      " |          def compute_metrics(self, x, y, y_pred, sample_weight):\n",
      " |              # This super call updates metrics from `compile` and returns\n",
      " |              # results for all metrics listed in `self.metrics`.\n",
      " |              metric_results = super().compute_metrics(\n",
      " |                  x, y, y_pred, sample_weight)\n",
      " |      \n",
      " |              # `metric_results` contains the previous result for\n",
      " |              # `custom_metric`, this is where we update it.\n",
      " |              self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
      " |              metric_results['custom_metric'] = self.custom_metric.result()\n",
      " |              return metric_results\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |          x: Input data.\n",
      " |          y: Target data.\n",
      " |          y_pred: Predictions returned by the model output of `model.call(x)`.\n",
      " |          sample_weight: Sample weights for weighting the loss function.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `dict` containing values that will be passed to\n",
      " |          `keras.callbacks.CallbackList.on_train_batch_end()`. Typically,\n",
      " |          the values of the metrics listed in `self.metrics` are returned.\n",
      " |          Example: `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  get_compile_config(self)\n",
      " |      Returns a serialized config with information for compiling the model.\n",
      " |      \n",
      " |      This method returns a config dictionary containing all the information\n",
      " |      (optimizer, loss, metrics, etc.) with which the model was compiled.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict containing information for compiling the model.\n",
      " |  \n",
      " |  get_metrics_result(self)\n",
      " |      Returns the model's metrics values as a dict.\n",
      " |      \n",
      " |      If any of the metric result is a dict (containing multiple metrics),\n",
      " |      each of them gets added to the top level returned dict of this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `dict` containing values of the metrics listed in `self.metrics`.\n",
      " |          Example: `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |  \n",
      " |  stateless_compute_loss(self, trainable_variables, non_trainable_variables, metrics_variables, x=None, y=None, y_pred=None, sample_weight=None, training=True)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.trainers.trainer.Trainer:\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  metrics_names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.src.trainers.trainer.Trainer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  jit_compile\n",
      " |  \n",
      " |  run_eagerly\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.layers.layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_loss(self, loss)\n",
      " |      Can be called inside of the `call()` method to add a scalar loss.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(Layer):\n",
      " |          ...\n",
      " |          def call(self, x):\n",
      " |              self.add_loss(ops.sum(x))\n",
      " |              return x\n",
      " |      ```\n",
      " |  \n",
      " |  add_metric(self, *args, **kwargs)\n",
      " |  \n",
      " |  add_variable(self, shape, initializer, dtype=None, trainable=True, autocast=True, regularizer=None, constraint=None, name=None)\n",
      " |      Add a weight variable to the layer.\n",
      " |      \n",
      " |      Alias of `add_weight()`.\n",
      " |  \n",
      " |  add_weight(self, shape=None, initializer=None, dtype=None, trainable=True, autocast=True, regularizer=None, constraint=None, aggregation='none', overwrite_with_gradient=False, name=None)\n",
      " |      Add a weight variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |          shape: Shape tuple for the variable. Must be fully-defined\n",
      " |              (no `None` entries). Defaults to `()` (scalar) if unspecified.\n",
      " |          initializer: Initializer object to use to populate the initial\n",
      " |              variable value, or string name of a built-in initializer\n",
      " |              (e.g. `\"random_normal\"`). If unspecified, defaults to\n",
      " |              `\"glorot_uniform\"` for floating-point variables and to `\"zeros\"`\n",
      " |              for all other types (e.g. int, bool).\n",
      " |          dtype: Dtype of the variable to create, e.g. `\"float32\"`. If\n",
      " |              unspecified, defaults to the layer's variable dtype\n",
      " |              (which itself defaults to `\"float32\"` if unspecified).\n",
      " |          trainable: Boolean, whether the variable should be trainable via\n",
      " |              backprop or whether its updates are managed manually. Defaults\n",
      " |              to `True`.\n",
      " |          autocast: Boolean, whether to autocast layers variables when\n",
      " |              accessing them. Defaults to `True`.\n",
      " |          regularizer: Regularizer object to call to apply penalty on the\n",
      " |              weight. These penalties are summed into the loss function\n",
      " |              during optimization. Defaults to `None`.\n",
      " |          constraint: Contrainst object to call on the variable after any\n",
      " |              optimizer update, or string name of a built-in constraint.\n",
      " |              Defaults to `None`.\n",
      " |          aggregation: Optional string, one of `None`, `\"none\"`, `\"mean\"`,\n",
      " |              `\"sum\"` or `\"only_first_replica\"`. Annotates the variable with\n",
      " |              the type of multi-replica aggregation to be used for this\n",
      " |              variable when writing custom data parallel training loops.\n",
      " |              Defaults to `\"none\"`.\n",
      " |          overwrite_with_gradient: Boolean, whether to overwrite the variable\n",
      " |              with the computed gradient. This is useful for float8 training.\n",
      " |              Defaults to `False`.\n",
      " |          name: String name of the variable. Useful for debugging purposes.\n",
      " |  \n",
      " |  compute_mask(self, inputs, previous_mask)\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |  \n",
      " |  get_build_config(self)\n",
      " |      Returns a dictionary with the layer's input shape.\n",
      " |      \n",
      " |      This method returns a config dict that can be used by\n",
      " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
      " |      Lookup tables) needed by the layer.\n",
      " |      \n",
      " |      By default, the config only contains the input shape that the layer\n",
      " |      was built with. If you're writing a custom layer that creates state in\n",
      " |      an unusual way, you should override this method to make sure this state\n",
      " |      is already created when Keras attempts to load its value upon model\n",
      " |      loading.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dict containing the input shape associated with the layer.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Return the values of `layer.weights` as a list of NumPy arrays.\n",
      " |  \n",
      " |  load_own_variables(self, store)\n",
      " |      Loads the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict from which the state of the model will be loaded.\n",
      " |  \n",
      " |  quantized_build(self, input_shape, mode)\n",
      " |  \n",
      " |  quantized_call(self, *args, **kwargs)\n",
      " |  \n",
      " |  rematerialized_call(self, layer_call, *args, **kwargs)\n",
      " |      Enable rematerialization dynamically for layer's call method.\n",
      " |      \n",
      " |      Args:\n",
      " |          layer_call: The original `call` method of a layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Rematerialized layer's `call` method.\n",
      " |  \n",
      " |  save_own_variables(self, store)\n",
      " |      Saves the state of the layer.\n",
      " |      \n",
      " |      You can override this method to take full control of how the state of\n",
      " |      the layer is saved upon calling `model.save()`.\n",
      " |      \n",
      " |      Args:\n",
      " |          store: Dict where the state of the model will be saved.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the values of `layer.weights` from a list of NumPy arrays.\n",
      " |  \n",
      " |  stateless_call(self, trainable_variables, non_trainable_variables, *args, return_losses=False, **kwargs)\n",
      " |      Call the layer without any side effects.\n",
      " |      \n",
      " |      Args:\n",
      " |          trainable_variables: List of trainable variables of the model.\n",
      " |          non_trainable_variables: List of non-trainable variables of the\n",
      " |              model.\n",
      " |          *args: Positional arguments to be passed to `call()`.\n",
      " |          return_losses: If `True`, `stateless_call()` will return the list of\n",
      " |              losses created during `call()` as part of its return values.\n",
      " |          **kwargs: Keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tuple. By default, returns `(outputs, non_trainable_variables)`.\n",
      " |              If `return_losses = True`, then returns\n",
      " |              `(outputs, non_trainable_variables, losses)`.\n",
      " |      \n",
      " |      Note: `non_trainable_variables` include not only non-trainable weights\n",
      " |      such as `BatchNormalization` statistics, but also RNG seed state\n",
      " |      (if there are any random operations part of the layer, such as dropout),\n",
      " |      and `Metric` state (if there are any metrics attached to the layer).\n",
      " |      These are all elements of state of the layer.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      model = ...\n",
      " |      data = ...\n",
      " |      trainable_variables = model.trainable_variables\n",
      " |      non_trainable_variables = model.non_trainable_variables\n",
      " |      # Call the model with zero side effects\n",
      " |      outputs, non_trainable_variables = model.stateless_call(\n",
      " |          trainable_variables,\n",
      " |          non_trainable_variables,\n",
      " |          data,\n",
      " |      )\n",
      " |      # Attach the updated state to the model\n",
      " |      # (until you do this, the model is still in its pre-call state).\n",
      " |      for ref_var, value in zip(\n",
      " |          model.non_trainable_variables, non_trainable_variables\n",
      " |      ):\n",
      " |          ref_var.assign(value)\n",
      " |      ```\n",
      " |  \n",
      " |  symbolic_call(self, *args, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.layers.layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the computations performed by the layer.\n",
      " |  \n",
      " |  dtype\n",
      " |      Alias of `layer.variable_dtype`.\n",
      " |  \n",
      " |  losses\n",
      " |      List of scalar losses from `add_loss`, regularizers and sublayers.\n",
      " |  \n",
      " |  metrics_variables\n",
      " |      List of all metric variables.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      List of all non-trainable layer state.\n",
      " |      \n",
      " |      This extends `layer.non_trainable_weights` to include all state used by\n",
      " |      the layer including state for metrics and `SeedGenerator`s.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weight variables of the layer.\n",
      " |      \n",
      " |      These are the weights that should not be updated by the optimizer during\n",
      " |      training. Unlike, `layer.non_trainable_variables` this excludes metric\n",
      " |      state and random seeds.\n",
      " |  \n",
      " |  path\n",
      " |      The path of the layer.\n",
      " |      \n",
      " |      If the layer has not been built yet, it will be `None`.\n",
      " |  \n",
      " |  quantization_mode\n",
      " |      The quantization mode of this layer, `None` if not quantized.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      List of all trainable layer state.\n",
      " |      \n",
      " |      This is equivalent to `layer.trainable_weights`.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weight variables of the layer.\n",
      " |      \n",
      " |      These are the weights that get updated by the optimizer during training.\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      The dtype of the state (weights) of the layer.\n",
      " |  \n",
      " |  variables\n",
      " |      List of all layer state, including random seeds.\n",
      " |      \n",
      " |      This extends `layer.weights` to include all state used by the layer\n",
      " |      including `SeedGenerator`s.\n",
      " |      \n",
      " |      Note that metrics variables are not included here, use\n",
      " |      `metrics_variables` to visit all the metric variables.\n",
      " |  \n",
      " |  weights\n",
      " |      List of all weight variables of the layer.\n",
      " |      \n",
      " |      Unlike, `layer.variables` this excludes metric state and random seeds.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.src.layers.layer.Layer:\n",
      " |  \n",
      " |  dtype_policy\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |      Settable boolean, whether this layer should be trainable or not.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.src.ops.operation.Operation:\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a symbolic operation.\n",
      " |      \n",
      " |      Only returns the tensor(s) corresponding to the *first time*\n",
      " |      the operation was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only returns the tensor(s) corresponding to the *first time*\n",
      " |      the operation was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output tensor or list of output tensors.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.src.saving.keras_saveable.KerasSaveable:\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      __reduce__ is used to customize the behavior of `pickle.pickle()`.\n",
      " |      \n",
      " |      The method returns a tuple of two elements: a function, and a list of\n",
      " |      arguments to pass to that function.  In this case we just leverage the\n",
      " |      keras saving library.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model\n",
    "\n",
    "There are two ways to create models through the TF 2 Keras API, either pass in a list of layers all at once, or add them one by one.\n",
    "\n",
    "Let's show both methods (its up to you to choose which method you prefer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - as a list of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=2),\n",
    "    Dense(units=2),\n",
    "    Dense(units=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - adding in layers one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and build a simple model and then compile it by defining our solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "\n",
    "# Final output node for prediction\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an optimizer and loss\n",
    "\n",
    "Keep in mind what kind of problem you are trying to solve:\n",
    "\n",
    "    # For a multi-class classification problem\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # For a binary classification problem\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # For a mean squared error regression problem\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Below are some common definitions that are necessary to know and understand to correctly utilize Keras:\n",
    "\n",
    "* Sample: one element of a dataset.\n",
    "    * Example: one image is a sample in a convolutional network\n",
    "    * Example: one audio file is a sample for a speech recognition model\n",
    "* Batch: a set of N samples. The samples in a batch are processed independently, in parallel. If training, a batch results in only one update to the model.A batch generally approximates the distribution of the input data better than a single input. The larger the batch, the better the approximation; however, it is also true that the batch will take longer to process and will still result in only one update. For inference (evaluate/predict), it is recommended to pick a batch size that is as large as you can afford without going out of memory (since larger batches will usually result in faster evaluation/prediction).\n",
    "* Epoch: an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n",
    "* When using validation_data or validation_split with the fit method of Keras models, evaluation will be run at the end of every epoch.\n",
    "* Within Keras, there is the ability to add callbacks specifically designed to be run at the end of an epoch. Examples of these are learning rate changes and model checkpointing (saving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Let's evaluate our performance on our training set and our test set. We can compare these two performances to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [257046.02053571428,\n",
       "  256727.57410714286,\n",
       "  256522.99767857144,\n",
       "  256373.04339285713,\n",
       "  256208.80839285714,\n",
       "  256017.87419642857,\n",
       "  255794.63875,\n",
       "  255536.61446428573,\n",
       "  255246.50839285715,\n",
       "  254920.9007142857,\n",
       "  254556.80571428573,\n",
       "  254155.80767857144,\n",
       "  253712.6569642857,\n",
       "  253222.941875,\n",
       "  252682.845,\n",
       "  252086.95839285714,\n",
       "  251436.20464285713,\n",
       "  250726.11482142858,\n",
       "  249952.45232142857,\n",
       "  249109.92089285713,\n",
       "  248200.0200892857,\n",
       "  247215.95776785715,\n",
       "  246154.1205357143,\n",
       "  245005.08839285714,\n",
       "  243780.42348214285,\n",
       "  242465.37642857144,\n",
       "  241055.46339285714,\n",
       "  239559.661875,\n",
       "  237966.36696428573,\n",
       "  236272.626875,\n",
       "  234471.03642857142,\n",
       "  232554.95428571428,\n",
       "  230538.98651785715,\n",
       "  228401.81401785713,\n",
       "  226150.31267857144,\n",
       "  223783.81348214287,\n",
       "  221290.60571428572,\n",
       "  218679.40830357143,\n",
       "  215924.69125,\n",
       "  213063.56241071428,\n",
       "  210046.38044642858,\n",
       "  206900.92839285714,\n",
       "  203611.78616071428,\n",
       "  200231.52544642857,\n",
       "  196671.46205357142,\n",
       "  192974.43410714285,\n",
       "  189174.22910714286,\n",
       "  185202.64232142858,\n",
       "  181108.9913392857,\n",
       "  176864.39651785715,\n",
       "  172504.71794642857,\n",
       "  168003.58785714285,\n",
       "  163362.08651785715,\n",
       "  158614.57803571428,\n",
       "  153737.69098214287,\n",
       "  148756.86517857143,\n",
       "  143625.381875,\n",
       "  138388.08901785716,\n",
       "  133087.5436607143,\n",
       "  127688.31861607142,\n",
       "  122186.69504464285,\n",
       "  116597.92147321429,\n",
       "  110948.68290178571,\n",
       "  105236.5175,\n",
       "  99482.9940625,\n",
       "  93701.20227678571,\n",
       "  87938.2564732143,\n",
       "  82171.90580357143,\n",
       "  76383.89745535715,\n",
       "  70635.64622767858,\n",
       "  64962.11716517857,\n",
       "  59347.544352678575,\n",
       "  53863.82444196429,\n",
       "  48459.28073660714,\n",
       "  43236.19125,\n",
       "  38164.600323660714,\n",
       "  33331.563203125,\n",
       "  28683.768895089284,\n",
       "  24321.479464285716,\n",
       "  20278.469587053572,\n",
       "  16523.323091517857,\n",
       "  13159.072672991071,\n",
       "  10194.291685267857,\n",
       "  7640.408490513393,\n",
       "  5576.274188058036,\n",
       "  4007.2731919642856,\n",
       "  2910.798597935268,\n",
       "  2304.2849581473215,\n",
       "  2099.1053069196428,\n",
       "  2047.892582310268,\n",
       "  2011.3148486328125,\n",
       "  1977.7155691964285,\n",
       "  1943.7098918805802,\n",
       "  1906.4392619977677,\n",
       "  1873.7697509765626,\n",
       "  1839.494091796875,\n",
       "  1807.7019468470983,\n",
       "  1773.0187297712052,\n",
       "  1742.6450809151786,\n",
       "  1706.0910637555803,\n",
       "  1671.919691685268,\n",
       "  1640.9999825613838,\n",
       "  1610.9062388392856,\n",
       "  1579.4019182477678,\n",
       "  1545.4603473772322,\n",
       "  1518.577080078125,\n",
       "  1485.8637158203126,\n",
       "  1457.9632101004465,\n",
       "  1424.8217975725447,\n",
       "  1394.5545382254463,\n",
       "  1364.850046735491,\n",
       "  1337.1091573660715,\n",
       "  1305.234978376116,\n",
       "  1277.8466336495535,\n",
       "  1248.961134905134,\n",
       "  1218.9898291015625,\n",
       "  1188.1648325892857,\n",
       "  1159.2657979910714,\n",
       "  1131.0403955078125,\n",
       "  1098.9464425223214,\n",
       "  1068.8702406529019,\n",
       "  1034.1244656808035,\n",
       "  1004.9060944475447,\n",
       "  974.5797921316964,\n",
       "  949.073662109375,\n",
       "  925.6563427734375,\n",
       "  898.7897991071428,\n",
       "  876.443902936663,\n",
       "  846.4307498604911,\n",
       "  829.9401977539062,\n",
       "  802.4260260881697,\n",
       "  777.9862841796875,\n",
       "  751.9605353655134,\n",
       "  724.9629045758928,\n",
       "  702.3697220284598,\n",
       "  679.32080078125,\n",
       "  655.4712688337054,\n",
       "  630.956916155134,\n",
       "  608.5175149972098,\n",
       "  585.3117515345982,\n",
       "  565.7603156389509,\n",
       "  542.5648521205358,\n",
       "  520.9779725864955,\n",
       "  501.187763671875,\n",
       "  483.32678588867185,\n",
       "  466.3137942940848,\n",
       "  448.6378601074219,\n",
       "  426.9133588518415,\n",
       "  411.4831403459821,\n",
       "  393.4418805803571,\n",
       "  376.3281863839286,\n",
       "  358.0179701450893,\n",
       "  344.0322297014509,\n",
       "  327.16663940429686,\n",
       "  312.23322230747766,\n",
       "  300.4992583356585,\n",
       "  285.098472202846,\n",
       "  270.99015023367747,\n",
       "  257.9235995047433,\n",
       "  242.57313310895648,\n",
       "  228.55255998883928,\n",
       "  217.23230460030692,\n",
       "  204.03783900669643,\n",
       "  192.49236258370536,\n",
       "  181.94021946498327,\n",
       "  170.34200622558595,\n",
       "  161.14263549804687,\n",
       "  149.8765545654297,\n",
       "  140.51057817731584,\n",
       "  131.7381551688058,\n",
       "  122.92249625069755,\n",
       "  114.93649026053292,\n",
       "  107.10216094970703,\n",
       "  99.21032762799945,\n",
       "  92.26787187848772,\n",
       "  84.84226850237165,\n",
       "  78.42208199637277,\n",
       "  73.06991385323661,\n",
       "  68.88644858224052,\n",
       "  63.60992636544364,\n",
       "  59.04246122087751,\n",
       "  54.492334987095425,\n",
       "  50.56024594988142,\n",
       "  46.57507073538644,\n",
       "  43.65467989240374,\n",
       "  41.20235630580357,\n",
       "  38.54703225272043,\n",
       "  36.89274923052107,\n",
       "  35.26179874965123,\n",
       "  33.39060076032366,\n",
       "  32.297111097063336,\n",
       "  31.1116964503697,\n",
       "  29.79240364074707,\n",
       "  28.935144544328963,\n",
       "  28.26140598842076,\n",
       "  27.343234013148717,\n",
       "  27.36963134765625,\n",
       "  26.79698026384626,\n",
       "  26.499113333565848,\n",
       "  25.893150612967354,\n",
       "  25.62219348362514,\n",
       "  25.393682414463587,\n",
       "  25.434924599783763,\n",
       "  25.196334571838378,\n",
       "  25.098290459769114,\n",
       "  25.021088354928153,\n",
       "  24.9933164705549,\n",
       "  24.817250110081265,\n",
       "  24.610098855154856,\n",
       "  24.39006670815604,\n",
       "  24.064426999773296,\n",
       "  24.527889840262276,\n",
       "  24.3929073878697,\n",
       "  24.59200389317104,\n",
       "  24.290332630702427,\n",
       "  24.540304859706335,\n",
       "  24.25796793256487,\n",
       "  24.22394993373326,\n",
       "  24.33741833278111,\n",
       "  24.367307946341377,\n",
       "  24.26597143990653,\n",
       "  24.236519066946848,\n",
       "  24.03049336024693,\n",
       "  24.29250689915248,\n",
       "  24.48969031197684,\n",
       "  24.059261234828405,\n",
       "  24.20917403084891,\n",
       "  24.062846450805665,\n",
       "  24.515583092825754,\n",
       "  24.111098273141042,\n",
       "  23.9794596862793,\n",
       "  24.218495330810548,\n",
       "  24.112635650634765,\n",
       "  24.419767041887557,\n",
       "  24.22412246159145,\n",
       "  24.0720441872733,\n",
       "  24.00706672668457,\n",
       "  24.368646545410158,\n",
       "  23.988784593854632,\n",
       "  24.33735505240304,\n",
       "  24.118764997209823,\n",
       "  24.143690828595844,\n",
       "  24.061329509190152,\n",
       "  24.44786605834961,\n",
       "  24.55346090044294,\n",
       "  24.511635371616908,\n",
       "  24.26320677621024,\n",
       "  24.089111475263323,\n",
       "  23.989297572544643,\n",
       "  24.744917046683174]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=range(len(loss)),y=loss)\n",
    "plt.title(\"Training Loss per Epoch\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare final evaluation (MSE) on training set and test set.\n",
    "\n",
    "These should hopefully be fairly close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = model.evaluate(X_train,y_train,verbose=0)\n",
    "test_score = model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.55682439531599"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.798187001546225"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[406.26343],\n",
       "       [625.07983],\n",
       "       [593.59314],\n",
       "       [573.62714],\n",
       "       [367.47824],\n",
       "       [580.6027 ],\n",
       "       [516.3    ],\n",
       "       [460.22568],\n",
       "       [550.58673],\n",
       "       [448.60873],\n",
       "       [613.2959 ],\n",
       "       [550.30396],\n",
       "       [420.10864],\n",
       "       [409.8501 ],\n",
       "       [652.86633],\n",
       "       [438.35947],\n",
       "       [509.70355],\n",
       "       [661.5566 ],\n",
       "       [664.221  ],\n",
       "       [566.93195],\n",
       "       [335.011  ],\n",
       "       [445.90964],\n",
       "       [383.43677],\n",
       "       [379.66046],\n",
       "       [567.987  ],\n",
       "       [612.09296],\n",
       "       [533.69293],\n",
       "       [428.89386],\n",
       "       [657.0607 ],\n",
       "       [415.08276],\n",
       "       [443.71158],\n",
       "       [486.30923],\n",
       "       [439.4752 ],\n",
       "       [683.53503],\n",
       "       [425.78995],\n",
       "       [418.6874 ],\n",
       "       [503.1647 ],\n",
       "       [551.8273 ],\n",
       "       [510.96967],\n",
       "       [396.29428],\n",
       "       [620.1216 ],\n",
       "       [417.63516],\n",
       "       [605.9426 ],\n",
       "       [447.04782],\n",
       "       [503.214  ],\n",
       "       [583.16064],\n",
       "       [670.66925],\n",
       "       [491.6024 ],\n",
       "       [319.3331 ],\n",
       "       [486.60828],\n",
       "       [518.5312 ],\n",
       "       [382.71024],\n",
       "       [543.24634],\n",
       "       [409.57797],\n",
       "       [643.1107 ],\n",
       "       [492.27206],\n",
       "       [629.48804],\n",
       "       [628.5606 ],\n",
       "       [448.15475],\n",
       "       [485.87952],\n",
       "       [492.33035],\n",
       "       [475.69794],\n",
       "       [684.4861 ],\n",
       "       [404.25476],\n",
       "       [702.8802 ],\n",
       "       [587.84174],\n",
       "       [584.55994],\n",
       "       [539.17975],\n",
       "       [485.75665],\n",
       "       [517.82074],\n",
       "       [362.08646],\n",
       "       [542.08276],\n",
       "       [572.03156],\n",
       "       [529.7627 ],\n",
       "       [454.82465],\n",
       "       [532.44696],\n",
       "       [508.45544],\n",
       "       [444.4056 ],\n",
       "       [544.70044],\n",
       "       [642.3479 ],\n",
       "       [467.1369 ],\n",
       "       [568.65845],\n",
       "       [692.49036],\n",
       "       [459.848  ],\n",
       "       [710.67194],\n",
       "       [473.8478 ],\n",
       "       [404.25616],\n",
       "       [586.54626],\n",
       "       [437.8215 ],\n",
       "       [490.16046],\n",
       "       [618.5658 ],\n",
       "       [440.54614],\n",
       "       [456.4309 ],\n",
       "       [436.31238],\n",
       "       [508.1484 ],\n",
       "       [609.9504 ],\n",
       "       [322.3879 ],\n",
       "       [437.33047],\n",
       "       [537.66205],\n",
       "       [519.9028 ],\n",
       "       [606.54333],\n",
       "       [526.7351 ],\n",
       "       [334.9314 ],\n",
       "       [577.5914 ],\n",
       "       [432.82236],\n",
       "       [563.9483 ],\n",
       "       [514.66473],\n",
       "       [392.0228 ],\n",
       "       [567.6409 ],\n",
       "       [455.911  ],\n",
       "       [449.57327],\n",
       "       [642.5517 ],\n",
       "       [525.6672 ],\n",
       "       [552.0467 ],\n",
       "       [418.70322],\n",
       "       [479.90872],\n",
       "       [587.9719 ],\n",
       "       [669.03143],\n",
       "       [702.20355],\n",
       "       [661.02466],\n",
       "       [561.94727],\n",
       "       [504.41043],\n",
       "       [391.29007],\n",
       "       [281.9948 ],\n",
       "       [480.78778],\n",
       "       [617.9032 ],\n",
       "       [374.2134 ],\n",
       "       [513.51825],\n",
       "       [512.27576],\n",
       "       [494.6914 ],\n",
       "       [481.63385],\n",
       "       [424.8122 ],\n",
       "       [494.66434],\n",
       "       [472.623  ],\n",
       "       [601.9391 ],\n",
       "       [575.005  ],\n",
       "       [415.9636 ],\n",
       "       [632.2133 ],\n",
       "       [467.5123 ],\n",
       "       [565.7332 ],\n",
       "       [406.6662 ],\n",
       "       [533.484  ],\n",
       "       [574.05035],\n",
       "       [357.92883],\n",
       "       [551.1896 ],\n",
       "       [604.85095],\n",
       "       [385.2252 ],\n",
       "       [543.72565],\n",
       "       [563.984  ],\n",
       "       [453.99207],\n",
       "       [633.7756 ],\n",
       "       [373.1417 ],\n",
       "       [475.4092 ],\n",
       "       [530.16583],\n",
       "       [373.19534],\n",
       "       [462.35925],\n",
       "       [437.36887],\n",
       "       [499.71695],\n",
       "       [346.94308],\n",
       "       [396.24692],\n",
       "       [606.0831 ],\n",
       "       [507.89963],\n",
       "       [469.75818],\n",
       "       [491.5713 ],\n",
       "       [536.60364],\n",
       "       [345.31842],\n",
       "       [513.5915 ],\n",
       "       [251.38142],\n",
       "       [505.32523],\n",
       "       [542.43054],\n",
       "       [490.56903],\n",
       "       [472.24612],\n",
       "       [393.4955 ],\n",
       "       [417.26862],\n",
       "       [550.93176],\n",
       "       [476.95383],\n",
       "       [581.37994],\n",
       "       [490.9674 ],\n",
       "       [602.4701 ],\n",
       "       [548.3496 ],\n",
       "       [543.30194],\n",
       "       [501.8112 ],\n",
       "       [647.44324],\n",
       "       [561.8009 ],\n",
       "       [579.37555],\n",
       "       [445.2174 ],\n",
       "       [416.52985],\n",
       "       [421.0515 ],\n",
       "       [570.5346 ],\n",
       "       [610.52203],\n",
       "       [438.8255 ],\n",
       "       [489.1685 ],\n",
       "       [589.20416],\n",
       "       [526.6729 ],\n",
       "       [358.21768],\n",
       "       [647.02264],\n",
       "       [529.33215],\n",
       "       [338.01492],\n",
       "       [493.89966],\n",
       "       [411.1523 ],\n",
       "       [608.1084 ],\n",
       "       [347.3649 ],\n",
       "       [523.7079 ],\n",
       "       [405.67038],\n",
       "       [259.00522],\n",
       "       [521.17804],\n",
       "       [341.71494],\n",
       "       [362.9102 ],\n",
       "       [577.8506 ],\n",
       "       [417.68906],\n",
       "       [552.3458 ],\n",
       "       [522.365  ],\n",
       "       [512.0057 ],\n",
       "       [325.52286],\n",
       "       [405.12326],\n",
       "       [603.8921 ],\n",
       "       [619.39307],\n",
       "       [604.7606 ],\n",
       "       [567.6965 ],\n",
       "       [474.58182],\n",
       "       [461.4935 ],\n",
       "       [509.68094],\n",
       "       [446.99258],\n",
       "       [512.57574],\n",
       "       [503.60657],\n",
       "       [401.1072 ],\n",
       "       [607.0318 ],\n",
       "       [258.73117],\n",
       "       [629.81726],\n",
       "       [590.60266],\n",
       "       [327.92664],\n",
       "       [480.71942],\n",
       "       [596.82367],\n",
       "       [379.30722],\n",
       "       [461.27716],\n",
       "       [325.78357],\n",
       "       [519.9732 ],\n",
       "       [410.61462],\n",
       "       [557.62585],\n",
       "       [643.49084],\n",
       "       [538.1467 ],\n",
       "       [504.41574],\n",
       "       [636.6225 ],\n",
       "       [516.51086],\n",
       "       [533.0186 ],\n",
       "       [520.09735],\n",
       "       [458.5575 ],\n",
       "       [507.0747 ],\n",
       "       [462.23328],\n",
       "       [593.1741 ],\n",
       "       [467.04837],\n",
       "       [428.21533],\n",
       "       [542.92456],\n",
       "       [495.01172],\n",
       "       [681.3526 ],\n",
       "       [373.66132],\n",
       "       [552.9735 ],\n",
       "       [579.3976 ],\n",
       "       [435.0165 ],\n",
       "       [544.3619 ],\n",
       "       [587.45667],\n",
       "       [580.6866 ],\n",
       "       [722.74384],\n",
       "       [433.78827],\n",
       "       [399.55917],\n",
       "       [314.75165],\n",
       "       [449.3715 ],\n",
       "       [389.0275 ],\n",
       "       [544.5414 ],\n",
       "       [524.0208 ],\n",
       "       [565.89056],\n",
       "       [449.10574],\n",
       "       [535.72797],\n",
       "       [382.709  ],\n",
       "       [502.7475 ],\n",
       "       [638.6875 ],\n",
       "       [497.77362],\n",
       "       [569.79364],\n",
       "       [471.25647],\n",
       "       [273.95135],\n",
       "       [518.6328 ],\n",
       "       [622.9433 ],\n",
       "       [351.34857],\n",
       "       [451.53647],\n",
       "       [500.51117],\n",
       "       [544.3127 ],\n",
       "       [613.3484 ],\n",
       "       [389.1045 ],\n",
       "       [450.48734],\n",
       "       [483.59534],\n",
       "       [599.79675],\n",
       "       [500.60007],\n",
       "       [322.21704],\n",
       "       [556.5154 ],\n",
       "       [445.71307],\n",
       "       [530.3348 ],\n",
       "       [516.57184],\n",
       "       [611.15717],\n",
       "       [417.96445],\n",
       "       [411.85953]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(y_test,columns=['Test Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402.296319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624.156198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>582.455066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578.588606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371.224104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>525.704657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>502.909473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>612.727910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>417.569725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>410.538250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Test Y\n",
       "0    402.296319\n",
       "1    624.156198\n",
       "2    582.455066\n",
       "3    578.588606\n",
       "4    371.224104\n",
       "..          ...\n",
       "295  525.704657\n",
       "296  502.909473\n",
       "297  612.727910\n",
       "298  417.569725\n",
       "299  410.538250\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.Series(test_predictions.reshape(300,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      406.263428\n",
       "1      625.079834\n",
       "2      593.593140\n",
       "3      573.627136\n",
       "4      367.478241\n",
       "          ...    \n",
       "295    530.334778\n",
       "296    516.571838\n",
       "297    611.157166\n",
       "298    417.964447\n",
       "299    411.859528\n",
       "Length: 300, dtype: float32"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat([pred_df,test_predictions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.columns = ['Test Y','Model Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402.296319</td>\n",
       "      <td>406.263428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624.156198</td>\n",
       "      <td>625.079834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>582.455066</td>\n",
       "      <td>593.593140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578.588606</td>\n",
       "      <td>573.627136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371.224104</td>\n",
       "      <td>367.478241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>525.704657</td>\n",
       "      <td>530.334778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>502.909473</td>\n",
       "      <td>516.571838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>612.727910</td>\n",
       "      <td>611.157166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>417.569725</td>\n",
       "      <td>417.964447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>410.538250</td>\n",
       "      <td>411.859528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Test Y  Model Predictions\n",
       "0    402.296319         406.263428\n",
       "1    624.156198         625.079834\n",
       "2    582.455066         593.593140\n",
       "3    578.588606         573.627136\n",
       "4    371.224104         367.478241\n",
       "..          ...                ...\n",
       "295  525.704657         530.334778\n",
       "296  502.909473         516.571838\n",
       "297  612.727910         611.157166\n",
       "298  417.569725         417.964447\n",
       "299  410.538250         411.859528\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare to the real test labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2599b2824c8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='Test Y',y='Model Predictions',data=pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['Error'] = pred_df['Test Y'] - pred_df['Model Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2599b269048>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(pred_df['Error'],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.197453664752528"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(pred_df['Test Y'],pred_df['Model Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.798188995783907"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pred_df['Test Y'],pred_df['Model Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.798187001546225"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essentially the same thing, difference just due to precision\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.176696533654085"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE\n",
    "test_score**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on brand new data\n",
    "\n",
    "What if we just saw a brand new gemstone from the ground? What should we price it at? This is the **exact** same procedure as predicting on a new test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[Feature1, Feature2]]\n",
    "new_gem = [[998,1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14117652, 0.53968792]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't forget to scale!\n",
    "scaler.transform(new_gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gem = scaler.transform(new_gem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[420.68692]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_gem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "later_model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[420.68692]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "later_model.predict(new_gem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
